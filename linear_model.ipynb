{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOyZm5M3s5gfl/Tl2Y2AL5O"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Image Classification using a linear model"
      ],
      "metadata": {
        "id": "p-D4wDRL4qnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Data"
      ],
      "metadata": {
        "id": "YRMYUiKs42Kb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gzb5IgR33-TK",
        "outputId": "48a22711-14a2-4433-da70-772b7ac8e8af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/754296579_30a9ae018c_n.jpg,daisy\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/18089878729_907ed2c7cd_m.jpg,dandelion\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/284497199_93a01f48f6.jpg,dandelion\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/3554992110_81d8c9b0bd_m.jpg,dandelion\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/4065883015_4bb6010cb7_n.jpg,daisy\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/roses/7420699022_60fa574524_m.jpg,roses\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/4558536575_d43a611bd4_n.jpg,dandelion\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/7568630428_8cf0fc16ff_n.jpg,daisy\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/7064813645_f7f48fb527.jpg,tulips\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/sunflowers/4933229095_f7e4218b28.jpg,sunflowers\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/14523675369_97c31d0b5b.jpg,daisy\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/sunflowers/21518663809_3d69f5b995_n.jpg,sunflowers\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/15782158700_3b9bf7d33e_m.jpg,dandelion\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713398906_28e59a225a_n.jpg,tulips\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/6770436217_281da51e49_n.jpg,tulips\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/8754822932_948afc7cef.jpg,dandelion\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/22873310415_3a5674ec10_m.jpg,daisy\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/sunflowers/5967283168_90dd4daf28_n.jpg,sunflowers\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/roses/483444865_65962cea07_m.jpg,roses\n",
            "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/2229906591_e953785d13.jpg,dandelion\n"
          ]
        }
      ],
      "source": [
        "!gsutil cat gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/train_set.csv | head -20"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify connection with GPU\n",
        "import tensorflow as tf\n",
        "print(tf.version.VERSION)\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "vLDMupM944w4",
        "outputId": "cf4a2a1f-2e67-4e67-89fd-e76040a2077b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Images"
      ],
      "metadata": {
        "id": "rXcZahmF5cmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "IMG_CHANNELS = 3"
      ],
      "metadata": {
        "id": "G1yi7OWp5GOk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_and_decode(filename, reshape_dims):\n",
        "  # Bytes Seq\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels = 3)\n",
        "  # Convert Int [0, 255] to float\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # Resize the image to the desired size, example: tf.image.resize(img, [256, 128])\n",
        "  return tf.image.resize(img, reshape_dims)"
      ],
      "metadata": {
        "id": "a7861htr5a8f"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}